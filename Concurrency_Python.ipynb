{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Concurrency-Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLMenQPjySa1/1i06RKV+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahgift/distributed-computing-explorations/blob/main/Concurrency_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J2FqEng9QMD"
      },
      "source": [
        "## Concurrency in Python\n",
        "\n",
        "* *[Watch Video Lesson 6.6:  Use concurrency methods in Python](https://www.safaribooksonline.com/videos/essential-machine-learning/9780135261118/9780135261118-EMLA_01_06_06)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krIvhgBnImBv"
      },
      "source": [
        "### Threads\n",
        "\n",
        "Threads are the beatup Pinto of concurrency in Python.  They lack the ability to scale to multiple cores and often cause performance problems.  Almost always you should choose some other method of concurrency in Python.\n",
        "\n",
        "*Typically they are used in situations where things are IO bound, not CPU bound.*\n",
        "\n",
        "![Pinto](https://homeprohub.files.wordpress.com/2013/03/cost-of-window-replacement.jpg)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ALnKSQUhhM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHKj4Ma-UbRE"
      },
      "source": [
        "##### Simple Threading Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay4BwuSLJcHx"
      },
      "source": [
        "import threading\n",
        "\n",
        "def fight_club(x):\n",
        "  \n",
        "    print(f\"Processing Thread# {num}: Calculating punch with attack strength {x} to the {x} power\\n\")\n",
        "    return x**x\n",
        "  \n",
        "workers = []\n",
        "for num in range(1,6):\n",
        "  print(f\"Queuing thread # {num}\\n\")\n",
        "  thread = threading.Thread(target=fight_club, args=(num,))\n",
        "  workers.append(thread)\n",
        "  thread.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDGnlhJG9V8H"
      },
      "source": [
        "#### Using the subprocess command\n",
        "\n",
        "A general purpose way to \"Shell Out\" to system commands\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTESMeN79XU0"
      },
      "source": [
        "import subprocess\n",
        "#res = subprocess.Popen(\"ls -l\", shell=True, stdout=subprocess.PIPE) #not ideal\n",
        "res = subprocess.Popen([\"ls\", \"-l\"], stdout=subprocess.PIPE)\n",
        "out = res.stdout.readlines()\n",
        "print(out)\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSfq5adfhpSq"
      },
      "source": [
        "#also worth noting in 3.7 subprocess.run(console_output=True)\n",
        "!python3 --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtBVGqwY9XY-"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxldNgl6-AOv"
      },
      "source": [
        "### Multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY5AmVgN_HF2"
      },
      "source": [
        "#### Mapping processes to Functions\n",
        "\n",
        "Processes are forked and run truly parallel (unlike threads)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZsdPvd-AYZ"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "\n",
        "def fight_club(x):\n",
        "  \n",
        "    sleep_time = random.randrange(0,3)\n",
        "    time.sleep(sleep_time)\n",
        "    timestamp = datetime.datetime.now()\n",
        "    print(f\"Calculating punch with attack strength {x} to the {x} power: @timestamp {timestamp} with sleep {sleep_time}\")\n",
        "    return x**x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    p = Pool(5)\n",
        "    print(p.map(fight_club, [1, 2, 3, 10, 100]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM1c0bhJCxOb"
      },
      "source": [
        "from multiprocessing import cpu_count\n",
        "cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlYpgAvaBVb_"
      },
      "source": [
        "#### Process Pool Joined on Queue (Threadlike behavior)\n",
        "\n",
        "Mimicks Threading interface, but with actual multi-core functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc8PKy12Bafu"
      },
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def f(q):\n",
        "    q.put([\"armbar\", \"kimura\",  \"Mata Leão\"])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    q = Queue()\n",
        "    p = Process(target=f, args=(q,))\n",
        "    p.start()\n",
        "    print(f\"Grabbing some attacks: {q.get()}\")    \n",
        "    p.join()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWGpAd50OrSp"
      },
      "source": [
        "### Async IO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIzv7oXKVkc4"
      },
      "source": [
        "#### Async IO in Python Examples\n",
        "\n",
        "More info here:  https://docs.python.org/3/library/asyncio.html\n",
        "\n",
        "**Using Python3 Async**\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "\n",
        "def send_async_firehose_events(count=100):\n",
        "    \"\"\"Async sends events to firehose\"\"\"\n",
        "\n",
        "    start = time.time() \n",
        "    client = firehose_client()\n",
        "    extra_msg = {\"aws_service\": \"firehose\"}\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = []\n",
        "    LOG.info(f\"sending aysnc events TOTAL {count}\",extra=extra_msg)\n",
        "    num = 0\n",
        "    for _ in range(count):\n",
        "        tasks.append(asyncio.ensure_future(put_record(gen_uuid_events(), client)))\n",
        "        LOG.info(f\"sending aysnc events: COUNT {num}/{count}\")\n",
        "        num +=1\n",
        "    loop.run_until_complete(asyncio.wait(tasks))\n",
        "    loop.close()\n",
        "    end = time.time()  \n",
        "    LOG.info(\"Total time: {}\".format(end - start))\n",
        "  ```\n",
        "\n",
        "**Using trollius library with Python 2:  DEPRECATED**\n",
        "\n",
        "```python\n",
        "\"\"\"Generates an Async MetaData call.  Note, this isn't available in Boto3\n",
        "In [56]: res = all_metadata_async()\n",
        "In [57]: res\n",
        "Out[57]: \n",
        "[('ami-manifest-path', <Response [200]>),\n",
        " ('instance-type', <Response [200]>),\n",
        " ('instance-id', <Response [200]>),\n",
        " ('iam', <Response [200]>),\n",
        " ('local-hostname', <Response [200]>),\n",
        " ('network', <Response [200]>),\n",
        " ('hostname', <Response [200]>),\n",
        " ('ami-id', <Response [200]>),\n",
        " ('instance-action', <Response [200]>),\n",
        " ('profile', <Response [200]>),\n",
        " ('reservation-id', <Response [200]>),\n",
        " ('security-groups', <Response [200]>),\n",
        " ('metrics', <Response [200]>),\n",
        " ('mac', <Response [200]>),\n",
        " ('public-ipv4', <Response [200]>),\n",
        " ('services', <Response [200]>),\n",
        " ('local-ipv4', <Response [200]>),\n",
        " ('placement', <Response [200]>),\n",
        " ('ami-launch-index', <Response [200]>),\n",
        " ('public-hostname', <Response [200]>),\n",
        " ('public-keys', <Response [200]>),\n",
        " ('block-device-mapping', <Response [200]>)]\n",
        "\"\"\"\n",
        "\n",
        "import requests\n",
        "import trollius\n",
        "\n",
        "def get_metadata_api_urls():\n",
        "    \"\"\"Retrieves the api endpoints for metadata\"\"\"\n",
        "\n",
        "    full_urls = {}\n",
        "    metadata_url = \"http://169.254.169.254/latest/meta-data/\"\n",
        "    resp = requests.get(metadata_url)\n",
        "    urls = resp.content.split()\n",
        "    for url in urls:\n",
        "        stripped_url = url.rstrip(\"/\")\n",
        "        full_urls[stripped_url]=(os.path.join(metadata_url, url))\n",
        "    return full_urls\n",
        "\n",
        "def _get(key_url):\n",
        "    key,url = key_url\n",
        "    return key, requests.get(url)\n",
        "\n",
        "def _do_calls(urls):\n",
        "    loop = trollius.get_event_loop()\n",
        "    futures = []\n",
        "    for url in urls:\n",
        "        futures.append(loop.run_in_executor(None, _get, url))\n",
        "    return futures\n",
        "\n",
        "@trollius.coroutine\n",
        "def call():\n",
        "    results = []\n",
        "    futures = _do_calls(get_metadata_api_urls().items())\n",
        "    for future in futures:\n",
        "        result = yield trollius.From(future)\n",
        "        results.append(result)\n",
        "    raise trollius.Return(results)\n",
        "\n",
        "def all_metadata_async():\n",
        "    \"\"\"Retrieves all available metadata for an instance async\"\"\"\n",
        "\n",
        "    loop = trollius.get_event_loop()\n",
        "    res = loop.run_until_complete(call())\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irg3LKBPSho9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS8BUP1DOw_c"
      },
      "source": [
        "### Serverless or FaaS (Functions as a service)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6NDMVEEQDAi"
      },
      "source": [
        "#### AWS Lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp4oYPABQ1Ct"
      },
      "source": [
        "#####  AWS Lambda and Chalice Example\n",
        "\n",
        "Standalone Lambda with Chalice:  http://chalice.readthedocs.io/en/latest/\n",
        "\n",
        "```python\n",
        "@app.lambda_function()\n",
        "def send_message(event, context):\n",
        "    \"\"\"Send a message to a channel\"\"\"\n",
        "\n",
        "    slack_client = SlackClient(SLACK_TOKEN)\n",
        "    res = slack_client.api_call(\n",
        "      \"chat.postMessage\",\n",
        "      channel=\"#general\",\n",
        "      text=event\n",
        "    )\n",
        "    return res\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzEspN5sQHMC"
      },
      "source": [
        "#### Fn Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgGOgph_PLns"
      },
      "source": [
        "##### Fn Project\n",
        "\n",
        "![Fn Project](https://camo.githubusercontent.com/aad13cfe0e267f38143fd8cc6816ab8adde37a56/687474703a2f2f666e70726f6a6563742e696f2f696d616765732f666e2d333030783132352e706e67)\n",
        "\n",
        "\n",
        "*   [FN Project](https://fnproject.io/)\n",
        "*   [FN Project Python Example](http://fnproject.io/tutorials/python/intro/)\n",
        "\n",
        "\n",
        "\n",
        "```bash\n",
        "\n",
        "fn init --runtime python --trigger http pythonfn\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "import fdk\n",
        "import json\n",
        "\n",
        "\n",
        "def handler(ctx, data=None, loop=None):\n",
        "    name = \"World\"\n",
        "    if data and len(data) > 0:\n",
        "        body = json.loads(data)\n",
        "        name = body.get(\"name\")\n",
        "    return {\"message\": \"Hello {0}\".format(name)}\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    fdk.handle(handler)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyqNyUBlO4lD"
      },
      "source": [
        "### Large Scale Concurrency Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oob6LCxSkB5"
      },
      "source": [
        "#### Larger Scale Concurrency\n",
        "\n",
        "\n",
        "\n",
        "*   [AWS Step Functions with Lambda](https://aws.amazon.com/step-functions/)\n",
        "\n",
        "![alt text](https://d1.awsstatic.com/product-marketing/Step%20Functions/OrderFullScreen.0e74c2f19d89a9325addb5bd746cd895b2e4c9c2.jpg)\n",
        "\n",
        "*   [AWS Batch](https://aws.amazon.com/batch/)\n",
        "![alt text](https://d1.awsstatic.com/Test%20Images/Kate%20Test%20Images/Dilithium_flowchart%20diagrams_v3_kw-02.322877d73eda8ed71a44db216a1d195550befac0.png)\n",
        "\n",
        "*   [RabbitMQ Worker Farms-IBM Developerworks Article](https://www.ibm.com/developerworks/cloud/library/cl-optimizepythoncloud1/index.html)\n",
        "\n",
        "![alt text](https://www.ibm.com/developerworks/cloud/library/cl-optimizepythoncloud2/figure1.gif)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj4o_5vbN7KK"
      },
      "source": [
        "### High Level Concurrency Overview for Machine Learning and HPC (High Performance Computing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XEgccwqObHz"
      },
      "source": [
        "#### Diagram of Python Performance Problems\n",
        "\n",
        "\n",
        "![63,000X Speedup for Matrix Multiply from Standard Python](https://user-images.githubusercontent.com/58792/45932870-37339000-bf38-11e8-8272-bf2addf56df1.png)\n",
        "\n",
        "Source:  [Dave Patterson, UC Berkeley](https://www2.eecs.berkeley.edu/Faculty/Homepages/patterson.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQdJElVtOkl-"
      },
      "source": [
        "#### Numba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-xqb3iUOqXN"
      },
      "source": [
        "[Numba](http://numba.pydata.org/)\n",
        "\n",
        "*   open source JIT (Just in Time Compiler)\n",
        "*   translates a subset of Python and Numpy code into fast machine code\n",
        "*   Can approach speed of C\n",
        "*   Can also parallize:  \"true threads\" and \"GPU\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gextduz_0M8e"
      },
      "source": [
        "##### Install Numba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZSQ1A2p0BBh"
      },
      "source": [
        "!apt-get install nvidia-cuda-toolkit\n",
        "!pip3 install numba\n",
        "\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/lib/x86_64-linux-gnu/libnvvm.so\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hKEZ1Tj1epy"
      },
      "source": [
        "##### Use Numba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFYboEOizxEA"
      },
      "source": [
        "from numba import (cuda, vectorize)\n",
        "import numba\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpFn79hqz9MZ"
      },
      "source": [
        "def real_estate_df():\n",
        "    \"\"\"30 Years of Housing Prices\"\"\"\n",
        "\n",
        "    df = pd.read_csv(\"https://raw.githubusercontent.com/noahgift/real_estate_ml/master/data/Zip_Zhvi_SingleFamilyResidence.csv\")\n",
        "    df.rename(columns={\"RegionName\":\"ZipCode\"}, inplace=True)\n",
        "    df[\"ZipCode\"]=df[\"ZipCode\"].map(lambda x: \"{:.0f}\".format(x))\n",
        "    df[\"RegionID\"]=df[\"RegionID\"].map(lambda x: \"{:.0f}\".format(x))\n",
        "    return df\n",
        "\n",
        "def numerical_real_estate_array(df):\n",
        "    \"\"\"Converts df to numpy numerical array\"\"\"\n",
        "\n",
        "    columns_to_drop = ['RegionID', 'ZipCode', 'City', 'State', 'Metro', 'CountyName']\n",
        "    df_numerical = df.dropna()\n",
        "    df_numerical = df_numerical.drop(columns_to_drop, axis=1)\n",
        "    return df_numerical.values\n",
        "\n",
        "def real_estate_array():\n",
        "    \"\"\"Returns Real Estate Array\"\"\"\n",
        "\n",
        "    df = real_estate_df()\n",
        "    rea = numerical_real_estate_array(df)\n",
        "    return np.float32(rea)\n",
        "  \n",
        "rea = real_estate_array()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPc7exa72bRv"
      },
      "source": [
        "##### Use Numba decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA-A6AkB1hgy"
      },
      "source": [
        "@numba.jit(nopython=True)\n",
        "def expmean_jit(rea):\n",
        "    \"\"\"Perform multiple mean calculations\"\"\"\n",
        "\n",
        "    val = rea.mean() ** 2\n",
        "    return val\n",
        "  \n",
        "expmean_jit(rea)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAAfm7yQ2g8Z"
      },
      "source": [
        "##### Multi-threaded numba\n",
        "\n",
        "True multi-threaded code (Warning will use all cores on anymachine that runs it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GwuihIV2mjw"
      },
      "source": [
        "@numba.jit(parallel=True)\n",
        "def add_sum_threaded(rea):\n",
        "    \"\"\"Use all the cores\"\"\"\n",
        "\n",
        "    x,_ = rea.shape\n",
        "    total = 0\n",
        "    for _ in numba.prange(x):\n",
        "        total += rea.sum()  \n",
        "        print(total)\n",
        "        \n",
        "add_sum_threaded(rea)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trrzMZEzOxPV"
      },
      "source": [
        "#### GPU "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smWYtiZRSdCE"
      },
      "source": [
        "Heavily used in Deep Learning\n",
        "\n",
        "*   NVidia\n",
        "  - Numba [CUDA GPU ](http://numba.pydata.org/numba-doc/latest/cuda/index.html)\n",
        "*  AMD\n",
        "  - Numba [AMD ROC GPU](http://numba.pydata.org/numba-doc/latest/roc/index.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW-Qc4Fh2TJk"
      },
      "source": [
        "##### Use GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Qebxvg1-OG"
      },
      "source": [
        "@vectorize(['float32(float32, float32)'], target='cuda')\n",
        "def add_ufunc(x, y):\n",
        "    return x + y\n",
        "  \n",
        "def cuda_operation():\n",
        "    \"\"\"Performs Vectorized Operations on GPU\"\"\"\n",
        "\n",
        "    x = real_estate_array()\n",
        "    y = real_estate_array()\n",
        "\n",
        "    print(\"Moving calculations to GPU memory\")\n",
        "    x_device = cuda.to_device(x)\n",
        "    y_device = cuda.to_device(y)\n",
        "    out_device = cuda.device_array(\n",
        "        shape=(x_device.shape[0],x_device.shape[1]), dtype=np.float32)\n",
        "    print(x_device)\n",
        "    print(x_device.shape)\n",
        "    print(x_device.dtype)\n",
        "\n",
        "    print(\"Calculating on GPU\")\n",
        "    add_ufunc(x_device,y_device, out=out_device)\n",
        "\n",
        "    out_host = out_device.copy_to_host()\n",
        "    print(f\"Calculations from GPU {out_host}\")\n",
        "    \n",
        "cuda_operation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2JT2c0YS7f5"
      },
      "source": [
        "#### TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztI-AeY4S9Oq"
      },
      "source": [
        "[Tensor Processing Unit](https://cloud.google.com/tpu/docs/tpus)\n",
        "\n",
        "\n",
        "\n",
        "*   \"Google’s custom-developed application-specific integrated circuits (ASICs) used to accelerate machine learning workloads\"\n",
        "*   Available both in colab notebooks and on Google Cloud\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IDGxxWAbWQs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}